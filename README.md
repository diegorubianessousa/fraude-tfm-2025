# TFM â€” Pipeline ETL Serverless en Google Cloud para DetecciÃ³n de Fraude

Este repositorio acompaÃ±a al Trabajo Fin de MÃ¡ster (TFM) y documenta la construcciÃ³n de un **pipeline ETL 100% serverless en Google Cloud Platform (GCP)** para preparar y exponer **datos financieros sintÃ©ticos** orientados a la **detecciÃ³n de fraude**.  
La soluciÃ³n automatiza la **ingesta** (GCS â†’ BigQuery), la **transformaciÃ³n** (SQL en BigQuery) y la **exposiciÃ³n** (Looker Studio), todo ello **orquestado con Cloud Composer (Airflow)**.

---

## ğŸ“Œ Alcance y objetivos

- DiseÃ±ar una **arquitectura cloud nativa** y **serverless**.
- Automatizar **ingesta**, **transformaciÃ³n** y **disponibilizaciÃ³n** de datos.
- Generar una **capa analÃ­tica clean** con **variables derivadas y mÃ©tricas de riesgo**.
- Exponer resultados en **dashboards** (Looker Studio) para negocio y analÃ­tica.

**Caso de uso**: DetecciÃ³n de patrones de fraude a partir de un dataset sintÃ©tico con millones de transacciones.

---

## ğŸ—ï¸ Arquitectura (alto nivel)

**Flujo ETL**  
`GCS (entrada CSV) â†’ Cloud Composer/Airflow â†’ BigQuery (raw â†’ clean) â†’ Looker Studio`

**Servicios GCP empleados**
- **Google Cloud Storage (GCS)**: *datalake* de entrada  
  - `gs://tfm-fraude-datalake-1754407122/entradas/`
- **Cloud Composer (Airflow)**: orquestaciÃ³n y monitorizaciÃ³n  
  - Entorno: `fraude-composer-env` (Composer 2.13.8 Â· Airflow 2.10.5)  
  - Bucket DAGs: `gs://us-central1-fraude-composer-8ec45861-bucket/dags/`
- **BigQuery**: almacenamiento y transformaciÃ³n (SQL)  
  - Proyecto: `fraude-tfm-2025`  
  - Dataset: `fraude_dataset`  
  - Tablas: `financial_transactions_raw` y `financial_transactions_clean`
- **Looker Studio**: visualizaciÃ³n interactiva

---

## ğŸ“‚ Estructura del repositorio
```bash
.
â”œâ”€â”€ fraude_pipeline_dag.py          # DAG de Airflow (Composer)
â”œâ”€â”€ README.md                       # Este documento
â”œâ”€â”€ looker/                         # Capturas de dashboards
â”‚   â”œâ”€â”€ dashboard_overview.png
â”‚   â”œâ”€â”€ analisis_fraude.png
â”‚   â”œâ”€â”€ patrones_riesgo.png
â”‚   â””â”€â”€ importes_fraude.png
â””â”€â”€ resultados/                     # Evidencias de ejecuciÃ³n
    â”œâ”€â”€ dag_ejecucion.png           # Airflow en verde (success)
    â””â”€â”€ bigquery_tablas.png         # ValidaciÃ³n tablas raw/clean
``` 
---

## âš™ï¸ Requisitos previos

- Proyecto en **GCP** con facturaciÃ³n activa.
- Permisos para: GCS, Composer, BigQuery y Looker Studio.
- **APIs habilitadas**: BigQuery, Cloud Composer, Cloud Storage.
- **gsutil** y **gcloud** (opcional si subes desde consola).

---

## ğŸš¦ Despliegue

### 1) Subir el DAG a Cloud Composer
Copia el DAG al bucket de Composer:

```bash
gsutil cp fraude_pipeline_dag.py gs://us-central1-fraude-composer-8ec45861-bucket/dags/
```

### 2) Ubicar los datos de entrada en GCS

```bash
gs://tfm-fraude-datalake-1754407122/entradas/financial_fraud_detection_dataset.csv
```
### 3) Ejecutar el pipeline
Desde la UI de airflow:
  1. Abre fraude_pipeline_dag.
  2. Trigger DAG.
  3. Verifica nodos en verde (success): inicio â†’ cargar_csv_gcs â†’ transformar_datos â†’ fin.

---

##ğŸ—„ï¸ Modelo de datos (BigQuery)

fraude-tfm-2025.fraude_dataset.financial_transactions_raw
Capa raw con los datos tal y como llegan desde GCS. Base para auditorÃ­a, reprocesos y trazabilidad.

fraude-tfm-2025.fraude_dataset.financial_transactions_clean
Capa clean con limpieza, normalizaciÃ³n y variables derivadas: mÃ©tricas temporales, bins de importe, scores de riesgo, contadores por ventana, indicadores por canal y dispositivo, etc. Es la tabla base para dashboards y analÃ­tica.
