# TFM â€” Pipeline ETL Serverless en Google Cloud para DetecciÃ³n de Fraude

Este repositorio acompaÃ±a al Trabajo Fin de MÃ¡ster (TFM) y documenta la construcciÃ³n de un **pipeline ETL 100% serverless en Google Cloud Platform (GCP)** para preparar y exponer **datos financieros sintÃ©ticos** orientados a la **detecciÃ³n de fraude**.  
La soluciÃ³n automatiza la **ingesta** (GCS â†’ BigQuery), la **transformaciÃ³n** (SQL en BigQuery) y la **exposiciÃ³n** (Looker Studio), todo ello **orquestado con Cloud Composer (Airflow)**.

---

## ğŸ“Œ Alcance y objetivos

- DiseÃ±ar una **arquitectura cloud nativa** y **serverless**.
- Automatizar **ingesta**, **transformaciÃ³n** y **disponibilizaciÃ³n** de datos.
- Generar una **capa analÃ­tica clean** con **variables derivadas y mÃ©tricas de riesgo**.
- Exponer resultados en **dashboards** (Looker Studio) para negocio y analÃ­tica.

**Caso de uso**: DetecciÃ³n de patrones de fraude a partir de un dataset sintÃ©tico con millones de transacciones.

---

## ğŸ—ï¸ Arquitectura (alto nivel)

**Flujo ETL**  
`GCS (entrada CSV) â†’ Cloud Composer/Airflow â†’ BigQuery (raw â†’ clean) â†’ Looker Studio`

**Servicios GCP empleados**
- **Google Cloud Storage (GCS)**: *datalake* de entrada  
  - `gs://tfm-fraude-datalake-1754407122/entradas/`
- **Cloud Composer (Airflow)**: orquestaciÃ³n y monitorizaciÃ³n  
  - Entorno: `fraude-composer-env` (Composer 2.13.8 Â· Airflow 2.10.5)  
  - Bucket DAGs: `gs://us-central1-fraude-composer-8ec45861-bucket/dags/`
- **BigQuery**: almacenamiento y transformaciÃ³n (SQL)  
  - Proyecto: `fraude-tfm-2025`  
  - Dataset: `fraude_dataset`  
  - Tablas: `financial_transactions_raw` y `financial_transactions_clean`
- **Looker Studio**: visualizaciÃ³n interactiva

---

## ğŸ“‚ Estructura del repositorio
```bash
.
â”œâ”€â”€ fraude_pipeline_dag.py          # DAG de Airflow (Composer)
â”œâ”€â”€ README.md                       # Este documento
â”œâ”€â”€ looker/                         # Capturas de dashboards
â”‚   â”œâ”€â”€ dashboard_overview.png
â”‚   â”œâ”€â”€ analisis_fraude.png
â”‚   â”œâ”€â”€ patrones_riesgo.png
â”‚   â””â”€â”€ importes_fraude.png
â””â”€â”€ resultados/                     # Evidencias de ejecuciÃ³n
    â”œâ”€â”€ dag_ejecucion.png           # Airflow en verde (success)
    â””â”€â”€ bigquery_tablas.png         # ValidaciÃ³n tablas raw/clean
``` 
---

## âš™ï¸ Requisitos previos

- Proyecto en **GCP** con facturaciÃ³n activa.
- Permisos para: GCS, Composer, BigQuery y Looker Studio.
- **APIs habilitadas**: BigQuery, Cloud Composer, Cloud Storage.
- **gsutil** y **gcloud** (opcional si subes desde consola).

---

## ğŸš¦ Despliegue

### 1) Subir el DAG a Cloud Composer
Copia el DAG al bucket de Composer:

```bash
gsutil cp fraude_pipeline_dag.py gs://us-central1-fraude-composer-8ec45861-bucket/dags/
```

### 2) Ubicar los datos de entrada en GCS

```bash
gs://tfm-fraude-datalake-1754407122/entradas/financial_fraud_detection_dataset.csv
```
### 3) Ejecutar el pipeline
Desde la UI de airflow:
  1. Abre fraude_pipeline_dag.
  2. Trigger DAG.
  3. Verifica nodos en verde (success): inicio â†’ cargar_csv_gcs â†’ transformar_datos â†’ fin.

---

## ğŸ—„ï¸ Modelo de datos (BigQuery)

fraude-tfm-2025.fraude_dataset.financial_transactions_raw
Capa raw con los datos tal y como llegan desde GCS. Base para auditorÃ­a, reprocesos y trazabilidad.

fraude-tfm-2025.fraude_dataset.financial_transactions_clean
Capa clean con limpieza, normalizaciÃ³n y variables derivadas: mÃ©tricas temporales, bins de importe, scores de riesgo, contadores por ventana, indicadores por canal y dispositivo, etc. Es la tabla base para dashboards y analÃ­tica.

---

## ğŸ§  TransformaciÃ³n principal (BigQuery)

La transformaciÃ³n de datos se realiza directamente en **BigQuery** a travÃ©s de SQL, orquestada desde el DAG `fraude_pipeline_dag.py`.  

### Objetivos principales
- ConversiÃ³n de la capa **raw** en **clean**.  
- DerivaciÃ³n de variables temporales (hora, dÃ­a, semana, trimestre).  
- NormalizaciÃ³n de campos (ubicaciones, categorÃ­as de dispositivos y canales).  
- CÃ¡lculo de mÃ©tricas de riesgo:  
  - `transaction_risk_score` (combinaciÃ³n de anomalÃ­as geogrÃ¡ficas, velocidad y desviaciÃ³n de gasto).  
  - SeÃ±ales de riesgo (`risk_signals_count`).  
  - Bins de importe y franjas horarias.  
  - Variables dummy por canal/dispositivo.  

### Ejemplo (extracto de la query dentro del DAG)

```sql
CREATE OR REPLACE TABLE `fraude-tfm-2025.fraude_dataset.financial_transactions_clean` AS
SELECT
  transaction_id,
  TIMESTAMP(timestamp) AS timestamp,
  EXTRACT(YEAR FROM TIMESTAMP(timestamp)) AS year,
  EXTRACT(MONTH FROM TIMESTAMP(timestamp)) AS month,
  ...
FROM `fraude-tfm-2025.fraude_dataset.financial_transactions_raw`
WHERE amount IS NOT NULL;

---

## ğŸ” ValidaciÃ³n (consultas Ãºtiles)

### Conteo de registros
```sql
SELECT 'raw'  AS capa, COUNT(*) AS n FROM `fraude-tfm-2025.fraude_dataset.financial_transactions_raw`
UNION ALL
SELECT 'clean' AS capa, COUNT(*) AS n FROM `fraude-tfm-2025.fraude_dataset.financial_transactions_clean`;
...

---

